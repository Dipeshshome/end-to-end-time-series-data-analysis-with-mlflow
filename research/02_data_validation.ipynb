{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'f:\\\\'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'artifacts/data_ingestion/Dataset/train_FD001.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\research\\02_data_validation.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m jet_data\u001b[39m=\u001b[39mpd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39martifacts/data_ingestion/Dataset/train_FD001.txt\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\"\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m jet_data\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mcycle\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mop1\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mop2\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39mop3\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor1\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor2\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor3\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor4\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor5\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m                     ,\u001b[39m\"\u001b[39m\u001b[39msensor6\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor7\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor8\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor9\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor10\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor11\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor12\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor13\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m                     ,\u001b[39m\"\u001b[39m\u001b[39msensor14\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor15\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor16\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor17\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor18\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor19\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                     ,\u001b[39m\"\u001b[39m\u001b[39msensor20\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor21\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor22\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39m\"\u001b[39m\u001b[39msensor23\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m jet_data\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\.venv\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\.venv\\lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'artifacts/data_ingestion/Dataset/train_FD001.txt'"
     ]
    }
   ],
   "source": [
    "jet_data=pd.read_csv('artifacts/data_ingestion/Dataset/train_FD001.txt', sep=\" \", header=None)\n",
    "jet_data.columns = [\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\"\n",
    "                    ,\"sensor6\",\"sensor7\",\"sensor8\",\"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\"\n",
    "                    ,\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "                    ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "\n",
    "jet_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DataValidationConfig:\n",
    "    root_dir: Path\n",
    "    STATUS_FILE: str\n",
    "    unzip_data_dir: Path\n",
    "    all_schema: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.TimeSeriesProject .constants import *\n",
    "from src.TimeSeriesProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH,\n",
    "        schema_filepath = SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_data_validation_config(self) -> DataValidationConfig:\n",
    "        config = self.config.data_validation\n",
    "        schema = self.schema.COLUMNS\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        data_validation_config = DataValidationConfig(\n",
    "        root_dir=config.root_dir,\n",
    "        STATUS_FILE=config.STATUS_FILE,\n",
    "        unzip_data_dir = config.unzip_data_dir,\n",
    "        all_schema=schema,\n",
    "        )\n",
    "\n",
    "        return data_validation_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from src.TimeSeriesProject import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataValiadtion:\n",
    "    def __init__(self, config: DataValidationConfig):\n",
    "        self.config = config\n",
    "\n",
    "    def RUL_calculator(self,df, df_max_cycles):\n",
    "        max_cycle = df_max_cycles[\"cycle\"]\n",
    "        result_frame = df.merge(max_cycle.to_frame(name='max_cycle'), left_on='id', right_index=True)\n",
    "        result_frame[\"RUL\"] = result_frame[\"max_cycle\"] - result_frame[\"cycle\"]\n",
    "        result_frame.drop(['max_cycle'], axis=1, inplace=True)\n",
    "        return result_frame\n",
    "\n",
    "\n",
    "    def validate_all_columns(self)-> bool:\n",
    "        try:\n",
    "            validation_status = None\n",
    "\n",
    "            data = pd.read_csv(self.config.unzip_data_dir,sep=\" \", header=None)\n",
    "            data.columns = [\"id\",\"cycle\",\"op1\",\"op2\",\"op3\",\"sensor1\",\"sensor2\",\"sensor3\",\"sensor4\",\"sensor5\"\n",
    "                    ,\"sensor6\",\"sensor7\",\"sensor8\",\"sensor9\",\"sensor10\",\"sensor11\",\"sensor12\",\"sensor13\"\n",
    "                    ,\"sensor14\",\"sensor15\",\"sensor16\",\"sensor17\",\"sensor18\",\"sensor19\"\n",
    "                    ,\"sensor20\",\"sensor21\",\"sensor22\",\"sensor23\"]\n",
    "            \n",
    "            data.drop(['sensor22', 'sensor23'], axis=1, inplace=True)\n",
    "            data.to_csv('artifacts/data_validation/output_data.csv', index=False)\n",
    "\n",
    "            jet_id_and_rul = data.groupby(['id'])[[\"id\" ,\"cycle\"]].max()\n",
    "            jet_id_and_rul.set_index('id', inplace=True)\n",
    "            jet_id_and_rul.to_csv('artifacts/data_validation/jet_id_and_rul.csv', index=False)\n",
    "\n",
    "\n",
    "            all_cols = list(data.columns)\n",
    "\n",
    "            all_schema = self.config.all_schema.keys()\n",
    "\n",
    "            for col in all_cols:\n",
    "                if col not in all_schema:\n",
    "                    validation_status = False\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "                else:\n",
    "                    validation_status = True\n",
    "                    with open(self.config.STATUS_FILE, 'w') as f:\n",
    "                        f.write(f\"Validation status: {validation_status}\")\n",
    "\n",
    "            data = self.RUL_calculator(data, jet_id_and_rul)\n",
    "            data.to_csv('artifacts/data_validation/relevent_data.csv', index=False)\n",
    "            \n",
    "\n",
    "            return validation_status\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'config\\\\config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\research\\02_data_validation.ipynb Cell 13\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     data_validation\u001b[39m.\u001b[39mRUL_calculator(df,df_max_cycles)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "\u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\research\\02_data_validation.ipynb Cell 13\u001b[0m line \u001b[0;36m2\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     config \u001b[39m=\u001b[39m ConfigurationManager()\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     data_validation_config \u001b[39m=\u001b[39m config\u001b[39m.\u001b[39mget_data_validation_config()\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     data_validation \u001b[39m=\u001b[39m DataValiadtion(config\u001b[39m=\u001b[39mdata_validation_config)\n",
      "\u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\research\\02_data_validation.ipynb Cell 13\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     config_filepath \u001b[39m=\u001b[39m CONFIG_FILE_PATH,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     params_filepath \u001b[39m=\u001b[39m PARAMS_FILE_PATH,\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     schema_filepath \u001b[39m=\u001b[39m SCHEMA_FILE_PATH):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig \u001b[39m=\u001b[39m read_yaml(config_filepath)\n\u001b[0;32m      <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparams \u001b[39m=\u001b[39m read_yaml(params_filepath)\n\u001b[0;32m     <a href='vscode-notebook-cell:/f%3A/Time%20Series%20Data%20Analysis%20%28Upwork%29/end-to-end-time-series-data-analysis-with-mlflow/research/02_data_validation.ipynb#X15sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema \u001b[39m=\u001b[39m read_yaml(schema_filepath)\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\.venv\\lib\\site-packages\\ensure\\main.py:849\u001b[0m, in \u001b[0;36mWrappedFunctionReturn.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    841\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    842\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mArgument \u001b[39m\u001b[39m{arg}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{valt}\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m{f}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    843\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mdoes not match annotation type \u001b[39m\u001b[39m{t}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    844\u001b[0m         )\n\u001b[0;32m    845\u001b[0m         \u001b[39mraise\u001b[39;00m EnsureError(msg\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    846\u001b[0m             arg\u001b[39m=\u001b[39marg, f\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, t\u001b[39m=\u001b[39mtempl, valt\u001b[39m=\u001b[39m\u001b[39mtype\u001b[39m(value)\n\u001b[0;32m    847\u001b[0m         ))\n\u001b[1;32m--> 849\u001b[0m return_val \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    850\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(return_val, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_templ):\n\u001b[0;32m    851\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m    852\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mReturn value of \u001b[39m\u001b[39m{f}\u001b[39;00m\u001b[39m of type \u001b[39m\u001b[39m{valt}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    853\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match annotation type \u001b[39m\u001b[39m{t}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    854\u001b[0m     )\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\src\\TimeSeriesProject\\utils\\common.py:36\u001b[0m, in \u001b[0;36mread_yaml\u001b[1;34m(path_to_yaml)\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39myaml file is empty\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     35\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m---> 36\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[1;32mf:\\Time Series Data Analysis (Upwork)\\end-to-end-time-series-data-analysis-with-mlflow\\src\\TimeSeriesProject\\utils\\common.py:29\u001b[0m, in \u001b[0;36mread_yaml\u001b[1;34m(path_to_yaml)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"reads yaml file and returns\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \n\u001b[0;32m     18\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[39m    ConfigBox: ConfigBox type\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 29\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(path_to_yaml) \u001b[39mas\u001b[39;00m yaml_file:\n\u001b[0;32m     30\u001b[0m         content \u001b[39m=\u001b[39m yaml\u001b[39m.\u001b[39msafe_load(yaml_file)\n\u001b[0;32m     31\u001b[0m         logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39myaml file: \u001b[39m\u001b[39m{\u001b[39;00mpath_to_yaml\u001b[39m}\u001b[39;00m\u001b[39m loaded successfully\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'config\\\\config.yaml'"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    data_validation_config = config.get_data_validation_config()\n",
    "    data_validation = DataValiadtion(config=data_validation_config)\n",
    "    data_validation.validate_all_columns()\n",
    "    df = pd.read_csv('artifacts/data_validation/output_data.csv')\n",
    "    df_max_cycles = pd.read_csv('artifacts/data_validation/jet_id_and_rul.csv')\n",
    "    data_validation.RUL_calculator(df,df_max_cycles)\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
